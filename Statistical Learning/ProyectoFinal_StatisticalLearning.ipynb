{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyecto Final del Curso Statistical Learning\n",
    "# Maestr√≠a en Ciencias de Datos\n",
    "# Universidad Galileo, Guatemala\n",
    "\n",
    "# Omar Meza\n",
    "# Julio 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import sklearn\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input csv file using pandas\n",
    "input = pd.read_csv(\"C:\\python\\SL\\data_titanic_proyecto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, these are the columns' headers with their id\n",
    "\n",
    "#0  'PassengerId': id \n",
    "#1  'Name': name\n",
    "#2  'Age': age\n",
    "#3  'SibSp': siblings/Spouse\n",
    "#4  'Parch': Parent/Child\n",
    "#5  'Ticket':\n",
    "#6  'Fare',\n",
    "#7  'Cabin', \n",
    "#8  'Embarked', \n",
    "#9  'passenger_class', \n",
    "#10 'passenger_sex',\n",
    "#11 'passenger_survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null %</th>\n",
       "      <th>Unique values %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>19.865320</td>\n",
       "      <td>9.988777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.430976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.833895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>77.104377</td>\n",
       "      <td>16.610550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.224467</td>\n",
       "      <td>0.448934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_class</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_sex</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_survived</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Null %  Unique values %\n",
       "PassengerId          0.000000       100.000000\n",
       "Name                 0.000000       100.000000\n",
       "Age                 19.865320         9.988777\n",
       "SibSp                0.000000         0.785634\n",
       "Parch                0.000000         0.785634\n",
       "Ticket               0.000000        76.430976\n",
       "Fare                 0.000000        27.833895\n",
       "Cabin               77.104377        16.610550\n",
       "Embarked             0.224467         0.448934\n",
       "passenger_class      0.000000         0.336700\n",
       "passenger_sex        0.000000         0.224467\n",
       "passenger_survived   0.000000         0.224467"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will help us to know what variables are more significant for the model\n",
    "# we can see the % of not present values per feature and the % of unique values per feature\n",
    "\n",
    "pd.DataFrame({'Null %': input.isnull().sum() * 100 / len(input), \n",
    "              'Unique values %': input.apply(lambda x: x.unique().size/x.size*100)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that, the lowest it is the Unique values %, the better the feature will be.\n",
    "  And, the lowest the Null % is, the better the feature is.\n",
    "\n",
    "From the above we can see that:\n",
    "\n",
    "(Col0): PassengerId is always different for each passenger, so it would not be useful for predicting.\n",
    "\n",
    "(Col1): Name is always different for each passenger, not useful for predicting\n",
    "\n",
    "(Col7): Cabin has 77% of nulls, so can't help too much\n",
    "\n",
    "We will need to remove the columns that are not helpful for the prediction, and for the ones that are useful, transform them in case there are Null values on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the features with Null % >0, fill the missing values \n",
    "# Null Age will be filled with the Age's mean in the input file\n",
    "# Embarked will be marked with an 'X' for the missing values\n",
    "\n",
    "def handle_nulls(df):\n",
    "    df.Age.fillna(value=round(df.Age.mean(),1),inplace=True)\n",
    "    df.Embarked.fillna(value='X',inplace=True)\n",
    "    df.Age.astype(int)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical features into numerical codes\n",
    "def handle_categorical(df):\n",
    "    df.passenger_sex = pd.Categorical(df.passenger_sex)\n",
    "    df.passenger_sex = df.passenger_sex.cat.codes\n",
    "    \n",
    "    df.passenger_class = pd.Categorical(df.passenger_class)\n",
    "    df.passenger_class = df.passenger_class.cat.codes\n",
    "    \n",
    "    df.Embarked = pd.Categorical(df.Embarked)\n",
    "    df.Embarked = df.Embarked.cat.codes\n",
    "    \n",
    "    df.passenger_survived = pd.Categorical(df.passenger_survived)\n",
    "    df.passenger_survived = df.passenger_survived.cat.codes\n",
    "    \n",
    "    # Create categories for Age's ranges: 0-8, 9-15, 16-18, 19-25, 26-40, 41-60, 61-100\n",
    "    bins = [0, 8, 15, 18, 25, 40, 60, 100]\n",
    "    #names = ['1', '2', '3', '4', '5', '6', '7']\n",
    "    names = [1,2,3,4,5,6,7]\n",
    "    df['Age_rng'] = pd.cut(df['Age'], bins, labels = names)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering to add more features that could describe better the target\n",
    "\n",
    "def feature_eng(df):\n",
    "    df['Family_Size'] = df['SibSp'] + df['Parch']\n",
    "    df['Fare_Per_Person'] = df['Fare']/(df['Family_Size']+1)\n",
    "    df['Age_Class'] = df['Age']*df['passenger_class']\n",
    "    df['Age_Fare'] = df['Age']*df['Fare']\n",
    "    df['Family_Size_x_class'] = df['Family_Size']*df['passenger_class']\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the features that we are not take into account\n",
    "\n",
    "def discriminate_features(df):\n",
    "    features = list(df.columns.values)  #names of columns in dataframe\n",
    "    features.remove('passenger_survived')  # the target variable (to predict)\n",
    "    features.remove('PassengerId')         # Remove all the not useful features\n",
    "    features.remove('Name')\n",
    "    features.remove('Cabin')\n",
    "    features.remove('Ticket')\n",
    "    #features.remove('Age')\n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "\n",
    "# Handle nulls in feature's values, according to what feature it is\n",
    "df = input\n",
    "df = handle_nulls(df)\n",
    "\n",
    "# Handle categorical values and assign a numeric value for each category\n",
    "df = handle_categorical(df)\n",
    "\n",
    "# Create some extra features to make the model more accurate\n",
    "df = feature_eng(df)\n",
    "\n",
    "# Isolate the features that are going to be included for the model calculation\n",
    "features = discriminate_features(df)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data that will be used to train, validate and test\n",
    "\n",
    "# Separate input data into train and test sets, 80% for train and 20% for test\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(df[features], df.passenger_survived, test_size=0.2)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[features], input.iloc[:, 11:12].values, test_size=0.2)\n",
    "\n",
    "\n",
    "# Separate train data into train and validation sets, 80% and 20% again, out of the 80% calculated above\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was taken from https://www.youtube.com/watch?v=eWswOZbSoCA\n",
    "def save_experiment(df, file):\n",
    "    if not os.path.isfile(file):\n",
    "        # create file if it does not exist\n",
    "        df.to_csv(file)\n",
    "    else: \n",
    "        # add dataframe information\n",
    "        df.to_csv(file, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>Age_rng</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Age_Fare</th>\n",
       "      <th>Family_Size_x_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.787500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231.288750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.614583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.375000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>59.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>427.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.505260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.229200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.707240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>34.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30.695800</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1718.964800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>598.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>460.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.325000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.561400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>23.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.275000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.143750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.575000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17931.522000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>70.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4970.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.483929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.487500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>33.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6.937500</td>\n",
       "      <td>33.0</td>\n",
       "      <td>915.750000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.186600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.229200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.707240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>31.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>813.750000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>27.720850</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1386.042500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>48.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.662500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.862500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4.467857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1219.725000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.775000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.150000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>32.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>26.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.887500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.075000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>29.70</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.862500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696.465000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.814575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.443725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1820.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.467857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.475000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>37.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.7000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.850000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1098.900000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>26.550000</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1539.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.495800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.899200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>494.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8.761100</td>\n",
       "      <td>38.0</td>\n",
       "      <td>499.382700</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>23.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.775000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.475000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>47.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2444.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15.035400</td>\n",
       "      <td>14.0</td>\n",
       "      <td>420.991200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.082400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.854200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.084000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>35.641650</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2708.765400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>54.955567</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7419.001500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.505260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>29.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>25.931250</td>\n",
       "      <td>59.4</td>\n",
       "      <td>1540.316250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.082400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25.929200</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1244.601600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>19.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.7500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>698.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1677.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>221.779200</td>\n",
       "      <td>59.4</td>\n",
       "      <td>6586.842240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>29.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.9500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.415000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>29.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>478.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>45.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1296.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  SibSp  Parch      Fare  Embarked  passenger_class  passenger_sex  \\\n",
       "82   29.70      0      0    7.7875         1                0              0   \n",
       "824   2.00      4      1   39.6875         2                0              1   \n",
       "94   59.00      0      0    7.2500         2                0              1   \n",
       "650  29.70      0      0    7.8958         2                0              1   \n",
       "367  29.70      0      0    7.2292         0                0              0   \n",
       "616  34.00      1      1   14.4000         2                0              1   \n",
       "141  22.00      0      0    7.7500         2                0              0   \n",
       "864  24.00      0      0   13.0000         2                1              1   \n",
       "174  56.00      0      0   30.6958         0                2              1   \n",
       "238  19.00      0      0   10.5000         2                1              1   \n",
       "772  57.00      0      0   10.5000         2                1              0   \n",
       "718  29.70      0      0   15.5000         1                0              1   \n",
       "470  29.70      0      0    7.2500         2                0              1   \n",
       "881  33.00      0      0    7.8958         2                0              1   \n",
       "816  23.00      0      0    7.9250         2                0              0   \n",
       "788   1.00      1      2   20.5750         2                0              1   \n",
       "737  35.00      0      0  512.3292         0                2              1   \n",
       "745  70.00      1      1   71.0000         2                2              1   \n",
       "182   9.00      4      2   31.3875         2                0              1   \n",
       "472  33.00      1      2   27.7500         2                1              0   \n",
       "321  27.00      0      0    7.8958         2                0              1   \n",
       "568  29.70      0      0    7.2292         0                0              1   \n",
       "637  31.00      1      1   26.2500         2                1              1   \n",
       "370  25.00      1      0   55.4417         0                2              1   \n",
       "736  48.00      1      3   34.3750         2                0              0   \n",
       "285  33.00      0      0    8.6625         0                0              1   \n",
       "13   39.00      1      5   31.2750         2                0              1   \n",
       "162  26.00      0      0    7.7750         2                0              1   \n",
       "543  32.00      1      0   26.0000         2                1              1   \n",
       "810  26.00      0      0    7.8875         2                0              1   \n",
       "..     ...    ...    ...       ...       ...              ...            ...   \n",
       "365  30.00      0      0    7.2500         2                0              1   \n",
       "888  29.70      1      2   23.4500         2                0              0   \n",
       "644   0.75      2      1   19.2583         0                0              0   \n",
       "383  35.00      1      0   52.0000         2                2              0   \n",
       "541   9.00      4      2   31.2750         2                0              0   \n",
       "273  37.00      0      1   29.7000         0                2              1   \n",
       "501  21.00      0      0    7.7500         1                0              0   \n",
       "11   58.00      0      0   26.5500         2                2              0   \n",
       "514  24.00      0      0    7.4958         2                0              1   \n",
       "427  19.00      0      0   26.0000         2                1              0   \n",
       "136  19.00      0      2   26.2833         2                2              0   \n",
       "529  23.00      2      1   11.5000         2                1              1   \n",
       "231  29.00      0      0    7.7750         2                0              1   \n",
       "110  47.00      0      0   52.0000         2                2              1   \n",
       "9    14.00      1      0   30.0708         0                1              0   \n",
       "313  28.00      0      0    7.8958         2                0              1   \n",
       "91   20.00      0      0    7.8542         2                0              1   \n",
       "1    38.00      1      0   71.2833         0                2              0   \n",
       "856  45.00      1      1  164.8667         2                2              0   \n",
       "42   29.70      0      0    7.8958         0                0              1   \n",
       "457  29.70      1      0   51.8625         2                2              0   \n",
       "105  28.00      0      0    7.8958         2                0              1   \n",
       "862  48.00      0      0   25.9292         2                2              0   \n",
       "145  19.00      1      1   36.7500         2                1              1   \n",
       "492  55.00      0      0   30.5000         2                2              1   \n",
       "527  29.70      0      0  221.7792         2                2              1   \n",
       "825  29.70      0      0    6.9500         1                0              1   \n",
       "639  29.70      1      0   16.1000         2                0              1   \n",
       "618   4.00      2      1   39.0000         2                1              0   \n",
       "331  45.50      0      0   28.5000         2                2              1   \n",
       "\n",
       "    Age_rng  Family_Size  Fare_Per_Person  Age_Class      Age_Fare  \\\n",
       "82        5            0         7.787500        0.0    231.288750   \n",
       "824       1            5         6.614583        0.0     79.375000   \n",
       "94        6            0         7.250000        0.0    427.750000   \n",
       "650       5            0         7.895800        0.0    234.505260   \n",
       "367       5            0         7.229200        0.0    214.707240   \n",
       "616       5            2         4.800000        0.0    489.600000   \n",
       "141       4            0         7.750000        0.0    170.500000   \n",
       "864       4            0        13.000000       24.0    312.000000   \n",
       "174       6            0        30.695800      112.0   1718.964800   \n",
       "238       4            0        10.500000       19.0    199.500000   \n",
       "772       6            0        10.500000       57.0    598.500000   \n",
       "718       5            0        15.500000        0.0    460.350000   \n",
       "470       5            0         7.250000        0.0    215.325000   \n",
       "881       5            0         7.895800        0.0    260.561400   \n",
       "816       4            0         7.925000        0.0    182.275000   \n",
       "788       1            3         5.143750        0.0     20.575000   \n",
       "737       5            0       512.329200       70.0  17931.522000   \n",
       "745       7            2        23.666667      140.0   4970.000000   \n",
       "182       2            6         4.483929        0.0    282.487500   \n",
       "472       5            3         6.937500       33.0    915.750000   \n",
       "321       5            0         7.895800        0.0    213.186600   \n",
       "568       5            0         7.229200        0.0    214.707240   \n",
       "637       5            2         8.750000       31.0    813.750000   \n",
       "370       4            1        27.720850       50.0   1386.042500   \n",
       "736       6            4         6.875000        0.0   1650.000000   \n",
       "285       5            0         8.662500        0.0    285.862500   \n",
       "13        5            6         4.467857        0.0   1219.725000   \n",
       "162       5            0         7.775000        0.0    202.150000   \n",
       "543       5            1        13.000000       32.0    832.000000   \n",
       "810       5            0         7.887500        0.0    205.075000   \n",
       "..      ...          ...              ...        ...           ...   \n",
       "365       5            0         7.250000        0.0    217.500000   \n",
       "888       5            3         5.862500        0.0    696.465000   \n",
       "644       1            3         4.814575        0.0     14.443725   \n",
       "383       5            1        26.000000       70.0   1820.000000   \n",
       "541       2            6         4.467857        0.0    281.475000   \n",
       "273       5            1        14.850000       74.0   1098.900000   \n",
       "501       4            0         7.750000        0.0    162.750000   \n",
       "11        6            0        26.550000      116.0   1539.900000   \n",
       "514       4            0         7.495800        0.0    179.899200   \n",
       "427       4            0        26.000000       19.0    494.000000   \n",
       "136       4            2         8.761100       38.0    499.382700   \n",
       "529       4            3         2.875000       23.0    264.500000   \n",
       "231       5            0         7.775000        0.0    225.475000   \n",
       "110       6            0        52.000000       94.0   2444.000000   \n",
       "9         2            1        15.035400       14.0    420.991200   \n",
       "313       5            0         7.895800        0.0    221.082400   \n",
       "91        4            0         7.854200        0.0    157.084000   \n",
       "1         5            1        35.641650       76.0   2708.765400   \n",
       "856       6            2        54.955567       90.0   7419.001500   \n",
       "42        5            0         7.895800        0.0    234.505260   \n",
       "457       5            1        25.931250       59.4   1540.316250   \n",
       "105       5            0         7.895800        0.0    221.082400   \n",
       "862       6            0        25.929200       96.0   1244.601600   \n",
       "145       4            2        12.250000       19.0    698.250000   \n",
       "492       6            0        30.500000      110.0   1677.500000   \n",
       "527       5            0       221.779200       59.4   6586.842240   \n",
       "825       5            0         6.950000        0.0    206.415000   \n",
       "639       5            1         8.050000        0.0    478.170000   \n",
       "618       1            3         9.750000        4.0    156.000000   \n",
       "331       6            0        28.500000       91.0   1296.750000   \n",
       "\n",
       "     Family_Size_x_class  \n",
       "82                     0  \n",
       "824                    0  \n",
       "94                     0  \n",
       "650                    0  \n",
       "367                    0  \n",
       "616                    0  \n",
       "141                    0  \n",
       "864                    0  \n",
       "174                    0  \n",
       "238                    0  \n",
       "772                    0  \n",
       "718                    0  \n",
       "470                    0  \n",
       "881                    0  \n",
       "816                    0  \n",
       "788                    0  \n",
       "737                    0  \n",
       "745                    4  \n",
       "182                    0  \n",
       "472                    3  \n",
       "321                    0  \n",
       "568                    0  \n",
       "637                    2  \n",
       "370                    2  \n",
       "736                    0  \n",
       "285                    0  \n",
       "13                     0  \n",
       "162                    0  \n",
       "543                    1  \n",
       "810                    0  \n",
       "..                   ...  \n",
       "365                    0  \n",
       "888                    0  \n",
       "644                    0  \n",
       "383                    2  \n",
       "541                    0  \n",
       "273                    2  \n",
       "501                    0  \n",
       "11                     0  \n",
       "514                    0  \n",
       "427                    0  \n",
       "136                    4  \n",
       "529                    3  \n",
       "231                    0  \n",
       "110                    0  \n",
       "9                      1  \n",
       "313                    0  \n",
       "91                     0  \n",
       "1                      2  \n",
       "856                    4  \n",
       "42                     0  \n",
       "457                    2  \n",
       "105                    0  \n",
       "862                    0  \n",
       "145                    2  \n",
       "492                    0  \n",
       "527                    0  \n",
       "825                    0  \n",
       "639                    0  \n",
       "618                    3  \n",
       "331                    0  \n",
       "\n",
       "[569 rows x 13 columns]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int8)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for the target variable\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the Support Vector Machine Training function\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_SVM(X, Y, x_validate, y_validate, C=1, Kernel='linear', Gamma=10):\n",
    "    start_time = time.time()\n",
    "    clf = SVC(C=C, kernel=Kernel, gamma=Gamma)\n",
    "    #clf.gamma='scale'\n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    # predict y based on validation data\n",
    "    y_pred = clf.predict(x_validate)\n",
    "    \n",
    "     # Get some KPIs for the model\n",
    "    score = clf.score(x_validate, y_validate)\n",
    "    accuracy = metrics.accuracy_score(y_validate, y_pred)    \n",
    "    recall = metrics.recall_score(y_validate, y_pred)\n",
    "    precision = metrics.precision_score(y_validate, y_pred)\n",
    "    \n",
    "    \n",
    "    output = {\n",
    "                'kernel':[Kernel],\n",
    "                'c':[C],\n",
    "                'gamma':[Gamma],\n",
    "                'score':[score],\n",
    "                'accuracy':[accuracy],\n",
    "                'recall':[recall],\n",
    "                'precision':[precision]\n",
    "            }\n",
    "    \n",
    "    df_output = pd.DataFrame(output)\n",
    "    save_experiment(df_output, 'train_SVM.csv')\n",
    "    joblib.dump(clf, 'python_obj_output\\clf_SVM.pkl')\n",
    "    print(\"--- Model processed in: %s seconds ---\" % (time.time() - start_time))\n",
    "    print(clf)\n",
    "    return(y_pred, clf)\n",
    "    \n",
    "    \n",
    "    #return(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\30177710\\appdata\\local\\continuum\\anaconda3\\envs\\galileo_tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model processed in: 87.13598370552063 seconds ---\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=12, kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred, SVM_model = train_SVM(X_train, Y_train, X_validate, Y_validate, C=1, Kernel='linear', Gamma=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8531468531468531\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: \", SVM_model.score(X_validate, Y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "\n",
      "\n",
      "Score:  0    0.762238\n",
      "Name: score, dtype: float64\n",
      "Accuracy: 0    0.762238\n",
      "Name: accuracy, dtype: float64\n",
      "Recall: 0    0.711864\n",
      "Name: recall, dtype: float64\n",
      "Precision: 0    0.711864\n",
      "Name: precision, dtype: float64\n",
      "\n",
      "Algorithm prediction:  [0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"RESULTS:\\n\\n\")\n",
    "print(\"Score: \", DecisionTree_Model['score'])\n",
    "print(\"Accuracy:\", DecisionTree_Model['accuracy'])\n",
    "print(\"Recall:\", DecisionTree_Model['recall'])\n",
    "print(\"Precision:\", DecisionTree_Model['precision'])\n",
    "print(\"\\nAlgorithm prediction: \", list(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_iris # datos de iris\n",
    "from sklearn.tree import DecisionTreeClassifier # √°rbol de decisi√≥n para clasificaci√≥n\n",
    "\n",
    "def train_DecisionTree(X, Y, x_validate, y_validate):\n",
    "    start_time = time.time()\n",
    "    clf = DecisionTreeClassifier() \n",
    "    clf.fit(X_train, Y_train) # entrenamiento del √°rbol\n",
    "    #print(tree)\n",
    "    \n",
    "    # predict y based on validation data\n",
    "    y_pred = clf.predict(x_validate)\n",
    "    \n",
    "     # Get some KPIs for the model\n",
    "    score = clf.score(x_validate, y_validate)\n",
    "    accuracy = metrics.accuracy_score(y_validate, y_pred)    \n",
    "    recall = metrics.recall_score(y_validate, y_pred)\n",
    "    precision = metrics.precision_score(y_validate, y_pred)\n",
    "    \n",
    "    \n",
    "    output = {\n",
    "                'score':[score],\n",
    "                'accuracy':[accuracy],\n",
    "                'recall':[recall],\n",
    "                'precision':[precision]\n",
    "            }\n",
    "    \n",
    "    df_output = pd.DataFrame(output)\n",
    "    save_experiment(df_output, 'train_DecisionTree.csv')\n",
    "    joblib.dump(clf, 'python_obj_output\\clf_decisionTree.pkl')\n",
    "    print(\"--- Model processed in: %s seconds ---\" % (time.time() - start_time))\n",
    "    print(clf)\n",
    "    return(y_pred, df_output) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model processed in: 0.012000560760498047 seconds ---\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "y_pred, DecisionTree_Model = train_DecisionTree(X_train, Y_train, X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "\n",
      "\n",
      "Score:  0    0.825175\n",
      "Name: score, dtype: float64\n",
      "Accuracy: 0    0.825175\n",
      "Name: accuracy, dtype: float64\n",
      "Recall: 0    0.79661\n",
      "Name: recall, dtype: float64\n",
      "Precision: 0    0.783333\n",
      "Name: precision, dtype: float64\n",
      "\n",
      "Algorithm prediction:  [0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree_Model.score(X_validate, Y_validate)\n",
    "print(\"RESULTS:\\n\\n\")\n",
    "print(\"Score: \", DecisionTree_Model['score'])\n",
    "print(\"Accuracy:\", DecisionTree_Model['accuracy'])\n",
    "print(\"Recall:\", DecisionTree_Model['recall'])\n",
    "print(\"Precision:\", DecisionTree_Model['precision'])\n",
    "print(\"\\nAlgorithm prediction: \", list(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(x_train, y_train, y_name):\n",
    "    y_total_rows = y_train.shape[0]\n",
    "    dif = y_train.unique().tolist()\n",
    "    for c in dif:\n",
    "        p = y_train[y_train == c].count() / y_total_rows\n",
    "        x = x.append({'col': y_name, 'x': c, 'prob': p}, ignore_index=True)    \n",
    "    xr = x_train.shape[0]\n",
    "    x_colnames = x_train.cols\n",
    "    for col in x_colnames:\n",
    "        col_distinct_values = x_train[col].unique().tolist()\n",
    "        for c in col_distinct_values:\n",
    "            cs = x_train[col]\n",
    "            p = cs[cs == c].count() / xr     \n",
    "    x_colnames = x_train.cols\n",
    "    ret = pd.DataFrame(cols=['col', 'x', 'prob'])\n",
    "    for col in x_cols:\n",
    "        cv = x_train[col].unique().tolist()\n",
    "        for c in col_distinct_values:\n",
    "            prob = x[(x['y']==y_value) & (x['col']==col)             \n",
    "            p2 = x[(x['c']==col) & (x['x']==c)]            \n",
    "            n = prob['prob'].iloc[0] * y_p\n",
    "            d = p2['prob'].iloc[0]\n",
    "            ret = ret.append({'col': col, 'x': c, 'prob': n/d)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Logistic(x_train, y_train, epochs, lr=0.0001, printEach=100, batch_size_=32):\n",
    "    batch_size = batch_size_   #32#x_train.shape[0]# batch_size_\n",
    "    feature_count = x_train.shape[1]\n",
    "    label_count = 1\n",
    "\n",
    "    training_epochs = epochs\n",
    "    learning_rate = lr\n",
    "    hidden_layers = feature_count - 1\n",
    "    cost_history = np.empty(shape=[1],dtype=float)\n",
    "\n",
    "    X = tf.placeholder(tf.float32,[batch_size,feature_count])\n",
    "    Y = tf.placeholder(tf.float32,[batch_size,label_count])\n",
    "    \n",
    "    b = tf.Variable(tf.zeros([batch_size,label_count]))\n",
    "    W = tf.Variable(tf.ones([feature_count,1])) \n",
    "    \n",
    "    #init = tf.contrib.layers.xavier_initializer()\n",
    "    h0 = tf.layers.dense(X, hidden_layers, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    h1 = tf.layers.dense(h0, label_count, activation=None)\n",
    "         \n",
    "    Y_hat = tf.nn.sigmoid(tf.add(tf.matmul(X, W), b)) \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #learning_rate2 = tf.compat.v1.train.exponential_decay(learning_rate,global_step,1000, 0.90, staircase=True)\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(-(Y*tf.log(Y_hat)+(1-Y)*tf.log(1-Y_hat)))\n",
    "    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=h1)\n",
    "    #cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=Y_hat)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost) \n",
    "    #optimizer =tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    predicted = tf.nn.sigmoid(h1)\n",
    "    correct_pred = tf.equal(tf.round(predicted), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    #batch_size=32\n",
    "    n_items=X_train.shape[0]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "    \n",
    "        for step in range(training_epochs + 1):\n",
    "            for i in range(0, n_items, batch_size):\n",
    "                #print(i,i+batch_size)\n",
    "                if (i+batch_size>n_items):\n",
    "                    i=n_items-batch_size\n",
    "                    \n",
    "                Y_send=y_train[i:i+batch_size]\n",
    "                X_send=x_train[i:i+batch_size]\n",
    "                #sess.run(optimizer, feed_dict={X: X_send, Y: Y_send})\n",
    "                loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={\n",
    "                                         X: X_send, Y: Y_send})\n",
    "\n",
    "            if step % printEach  == 0:\n",
    "                print(\"Epoch: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(step, loss, acc))\n",
    "                \n",
    "            cost_history = np.append(cost_history, acc)     \n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0\tLoss: 4.279\tAcc: 78.12%\n",
      "Epoch:    50\tLoss: 3.538\tAcc: 78.12%\n",
      "Epoch:   100\tLoss: 3.070\tAcc: 71.88%\n",
      "Epoch:   150\tLoss: 3.145\tAcc: 75.00%\n",
      "Epoch:   200\tLoss: 2.943\tAcc: 75.00%\n",
      "Epoch:   250\tLoss: 2.124\tAcc: 78.12%\n",
      "Epoch:   300\tLoss: 3.611\tAcc: 56.25%\n",
      "Epoch:   350\tLoss: 3.549\tAcc: 43.75%\n",
      "Epoch:   400\tLoss: 3.513\tAcc: 37.50%\n",
      "Epoch:   450\tLoss: 3.356\tAcc: 40.62%\n",
      "Epoch:   500\tLoss: 3.396\tAcc: 37.50%\n",
      "Epoch:   550\tLoss: 3.505\tAcc: 37.50%\n",
      "Epoch:   600\tLoss: 3.686\tAcc: 34.38%\n",
      "Epoch:   650\tLoss: 3.650\tAcc: 37.50%\n",
      "Epoch:   700\tLoss: 3.503\tAcc: 37.50%\n",
      "Epoch:   750\tLoss: 4.375\tAcc: 34.38%\n",
      "Epoch:   800\tLoss: 2.350\tAcc: 68.75%\n",
      "Epoch:   850\tLoss: 2.142\tAcc: 75.00%\n",
      "Epoch:   900\tLoss: 2.660\tAcc: 62.50%\n",
      "Epoch:   950\tLoss: 4.429\tAcc: 40.62%\n",
      "Epoch:  1000\tLoss: 2.133\tAcc: 71.88%\n"
     ]
    }
   ],
   "source": [
    "x=train_Logistic(X_train, Y_train, 1000, 0.00001, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecuci√≥n de los 4 algoritmos para obtener las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\30177710\\appdata\\local\\continuum\\anaconda3\\envs\\galileo_tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model processed in: 89.86314010620117 seconds ---\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=12, kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "y_pred_SVM, SVM_model = train_SVM(X_train, Y_train, X_validate, Y_validate, C=1, Kernel='linear', Gamma=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model processed in: 0.017000913619995117 seconds ---\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "y_pred_DecisionTree, DecisionTree_Model = train_DecisionTree(X_train, Y_train, X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = y_pred_SVM + y_pred_DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAlgorithms(X, Y):\n",
    "    y_pred_DecisionTree, DecisionTree_Model = train_DecisionTree(X, Y, X_validate, Y_validate)\n",
    "    y_pred_SVM, SVM_model = train_SVM(X_train, Y_train, X_validate, Y_validate, C=1, Kernel='linear', Gamma=12)\n",
    "    res = y_pred_SVM + y_pred_DecisionTree \n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model processed in: 0.012000799179077148 seconds ---\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\30177710\\appdata\\local\\continuum\\anaconda3\\envs\\galileo_tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model processed in: 62.94960045814514 seconds ---\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=12, kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "res=runAlgorithms(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 2, 1, 0, 2, 0, 2, 0, 0, 1, 1, 2, 2, 0, 2, 2, 0, 0, 2, 2, 0, 2,\n",
       "       0, 2, 1, 0, 2, 0, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2, 1, 1, 2, 1, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 0, 0,\n",
       "       0, 2, 0, 2, 0, 0, 2, 1, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2, 2,\n",
       "       0, 2, 1, 2, 2, 2, 1, 1, 2, 1, 0, 0, 1, 0, 2, 2, 1, 0, 1, 1, 0, 2,\n",
       "       1, 2, 2, 1, 1, 2, 1, 0, 2, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esta es el resultado final, es necesario sacar la moda\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependiendo de \"la moda\" ese ser√° el resultado final de la combinaci√≥n de modelos\n",
    "\n",
    "res[res==1]=0\n",
    "res[res==2]=1\n",
    "res[res==3]=1\n",
    "res[res==4]=1\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Este es el resultado final de la predicci√≥n\n",
    "# para los valores de prueba\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una t√©cnica utilizada cuando se cuenta con un dataset muy peque√±o y que por ende tiene pocas observaciones, consiste en utilizar varias veces (k veces) la misma data, pero cada una de estas veces se realiza un split distinto de las observaciones, por lo que en cada una de las K veces que el dataset sea utilizado, tendr√° diferentes observaciones para Training y Testing.\n",
    "\n",
    "Para este proyecto podr√≠a haber sido √∫til dado que no se cuenta con un n√∫mero tan grande de observaciones, se pudo haber realizado varios experimentos con la misma data, pero dividida de forma diferente en cada una de las veces, por lo que hubieramos podido obtener K modelos.  Finalmente hubi√©semos tenido que decidir cu√°l de los K modelos era el que mejor describia al dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestreo Bootstrap\n",
    "Este es √∫til cuando se necesita generar muchas sub muestras de la muestra principal, es decir, si se tiene una muestra total (poblaci√≥n) de 1000 observaciones, al realizar bootstrap se indica cu√°ntas sub muestras se quieren generar a partir de la muestra principal.  Estas muestras pueden ser con o sin reemplazo, es decir, puede haber observaciones repetidas dentro de la misma sub muestra, sin embargo, esto no afecta el resultado.  \n",
    "En este proyecto no fue necesario utilizarlo, sin embargo, puede ser √∫til en caso se quiera generar varios modelos a partir de una misma muestra, y al final elegir el mejor de todos, resultado de hacer fit sobre cada una de las sub muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "* Con este proyecto se pudo poner en pr√°ctica diferentes t√©cnicas que se vieron durante el curso, tales como Ensemble Learning y de qu√© forma se vuelven modelos colaborativos entre ellos para brindar un solo resultado final.\n",
    "* A diferencia de las tareas de clase, en donde ya se nos daba la data lista para trabajar, durante este proyecto tuvimos que poner en pr√°ctica tareas de limpieza de data, ya que el dataset original conten√≠a informaci√≥n incompleta y algunas features poco √∫tiles para nuestro prop√≥sito, por lo que tuvimos que llenar los datos vacios y dejar atr√°s las featues innecesarias.\n",
    "* Algo que debo mencionar aunque no est√© del todo ligado al proyecto es que, este y los dem√°s proyectos de Econometr√≠a, sumado a la carga laboral, definitivamente nos hicieron dar todo lo posible y tratar de administrar de mejor forma nuestro tiempo.  Dejo esto como algo aprendido durante este trimestre.\n",
    "* Aprendi de qu√© forma puede guardarse persistentemente un modelo que fue generado anteriormente, sin necesidad de tener que entrenarlo nuevamente.\n",
    "\n",
    "\n",
    "# Dificultades:\n",
    "\n",
    "* Debo mencionar que al igual que durante la tarea de regresi√≥n log√≠stica, volv√≠ a tener dificultades para armar la funci√≥n de entrenamiento en tensorflow para √©sta, realic√© varias pruebas y finalmente dej√© el mejor resultado que obtuve durante los d√≠as que estuve realizando el proyecto.\n",
    "* Para la realizaci√≥n del algoritmo de Naive Bayes, estuve un poco confundido, ya que en el video de √©sta clase se realiza un ejemplo co GaussianNB de Sklearn, sin embargo, en el proyecto habia que utilizar un enfoque distinto al visto en clase, lo cual caus√≥ un poco de confusi√≥n.\n",
    "\n",
    "\n",
    "# Lecciones aprendidas:\n",
    "\n",
    "* Aprendi que debo organizar de mejor forma mi tiempo, ya que por querer abarcar un poco en varias cosas al final hac√≠a nada en todas.  Esta definitivamente es una lecci√≥n aprendida, al final logr√© organizar un poco mejor mi tiempo, sin embargo, si lo hubiera hecho desde el inicio no hubiera tenido mayores inconvenientes.\n",
    "* Pase lo que pase, definitivamente me voy a inscribir en alg√∫n curso de Tensorflow, si bien logr√© defenderme en las tareas, s√© que no lo domino y que por ser la base de todo, tengo que aprenderlo para no depender de Google en su aplicaci√≥n.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
